[config]
test =

[root]
data = ~/data

[ray]

[eval]
problem = wuji.problem.mdp.netease.blockmaze.Problem	wuji.problem.mdp.netease.blockmaze.wrap.reward.goal	wuji.problem.mdp.netease.blockmaze.wrap.reward.valid	wuji.problem.mdp.netease.blockmaze.wrap.reward.invalid	wuji.problem.mdp.netease.blockmaze.wrap.objective.final_distance	wuji.problem.mdp.netease.blockmaze.wrap.objective.position_set	wuji.problem.wrap.hparam.decision	wuji.problem.mdp.wrap.hparam.reward	wuji.problem.mdp.wrap.hparam.final_reward
render = 0

[sample]
train = 300
eval = 3

[model]
root = ~/model/wuji
keep = 5
module = wuji.model.pth.conv.BlockMaze
critic = wuji.model.pth.wrap.critic.conv.flat_hidden0
init = wuji.model.pth.wrap.init.config

[ea]
population = 30
offspring =
offspring_recent = 30
mix_elite = 1
mix_population =
runner = wuji.ea.runner.Runner	wuji.ea.runner.wrap.ray
evaluator = wuji.evaluator.mdp.pth.rl.dqn.Evaluator
schedule = learn:1
mating = wuji.ea.mating.non_dominated.nsga_ii.NSGA_II
selection = wuji.ea.selection.non_dominated.nsga_ii.Selection	wuji.ea.selection.wrap.plot.record	wuji.ea.selection.wrap.plot.visualize	wuji.ea.selection.wrap.plot.color	wuji.ea.selection.wrap.plot.point
optimizer = wuji.ea.optimizer.Async	wuji.ea.optimizer.wrap.age	wuji.ea.optimizer.wrap.record.create	wuji.ea.optimizer.wrap.record.save	wuji.wrap.record.profile	wuji.ea.optimizer.wrap.record.result.population	wuji.ea.optimizer.wrap.record.result.variation.improve	wuji.ea.optimizer.wrap.record.decision.blob	wuji.ea.optimizer.wrap.record.decision.hparam	wuji.ea.optimizer.wrap.wuji.bug_set(True)
stopper = wuji.stopper.Never

[runner]
variation = crossover mutate
stopper = wuji.stopper.cost.relative()	wuji.stopper.wrap.scalar.debug.csv()	wuji.stopper.wrap.outcome.config	wuji.stopper.wrap.outcome.result	wuji.stopper.wrap.duration()

[crossover]
blob = wuji.ea.crossover.blob.pth.single_point.Split
real = wuji.ea.crossover.real.sbx.Crossover
integer = wuji.ea.crossover.integer.single_point.Crossover

[crossover_prob]
blob = 1
real = 1
integer = 1

[mutation]
blob = wuji.ea.mutation.Useless
real = wuji.ea.mutation.real.pm.Mutation
integer = wuji.ea.mutation.integer.bitwise.Mutation

[mutation_prob]

[stopper]
cost = 10000
skip = 10
duration = 12h
patience = 3
trial = 100
record = 0

[stopper_outcome]
scalar = outcome.result['fitness']

[crossover_sbx]
distribution_index = 20

[mutation_gaussian]
stddev = 0.005

[mutation_pm]
distribution_index = 20

[mating]
filter = digest decision result

[tournament]
competitors = 2
compare = (individual['result']['fitness'], individual['age'])
point = individual['result']['point']
probability = 0.7

[non_dominated]
dominate = dominate_max(individual1['result']['objective'], individual2['result']['objective'])
marker_point = o * < . v x ^ >
marker_line = - -- -.-

[nsga_ii]
density = (individual['crowding_distance'], individual['age'])

[train]
optimizer = torch.optim.Adam(params, lr, betas=(0.9, 0.999), eps=1e-8)
lr = 0.00025
lr_ = 0
batch_size = 128
batch_size_ = 0
record = 0
stopper = wuji.stopper.Never	wuji.stopper.wrap.scalar.debug.csv()	wuji.stopper.wrap.outcome.config	wuji.stopper.wrap.outcome.result

[rl]
discount = 0.99
discount_ = 0
wrap =

[pg]
prob_min = 0.01
prob_min_ = 0
prob_min_opponent_ = 0
# (reward / 5000).clip(-100, 100)
# (reward - reward.mean()) / (reward.std() + 1)
# (reward - reward.mean()) / (reward.std() + np.finfo(np.float32).eps)
# (reward - reward.mean()) / reward.std().clip(1)
norm = reward
agent_train =
agent_eval =
# explore = numpy

[ac]
# truncation = 5
truncation_ = 0
gae = 0
# l1_loss
# mse_loss
# smooth_l1_loss
loss_critic = mse_loss

[ac_weight_loss]
policy = 1
policy_ = 0
critic = 1
critic_ = 0
entropy = 0.0001
entropy_ = 0

[a3c]
# parallel = 16
wrap =

[impala]
# parallel = 1
rho = 1
c = 1
wrap =

[ppo]
# parallel = 1
norm_advantage = (advantage - advantage.mean()) / (advantage.std() + np.finfo(np.float32).eps)
epsilon = 0.2
epoch = 10
wrap =

[dqn]
epsilon = 1
epsilon_ = 1
next_epsilon = max(epsilon - 0.001, 0.05)
capacity = 10000
update = 25
loss = mse_loss
buffer = 100
agent_train =
agent_eval =
wrap = wuji.rl.pth.dqn.wrap.buffer.fifo	wuji.rl.pth.dqn.wrap.double

[record]
recorder = wuji.recorder.Process	wuji.recorder.tensorboard	wuji.recorder.problem	wuji.recorder.mdp.pth.model
maxsize = 1000
scalar = 10
scalars = 10
vector = 10
_histogram_dict = 0
histogram_dict = 5m
histogram_list = 2m
rollout = 5m
_rollout = 0
classify = 30m
_classify = 0
embedding = 5m
distribution = 5m
plot = 5m
_plot = 0
freq = 30m
_freq = 1
save = 10m
_save = 0
metric = 30m
_metric = 0
memory = 1m

[visualizer]
interval = 1

[hypervolume]
ref =

[blockmaze_weight_reward]
valid = -0.01
invalid = 1

[blockmaze_weight_reward_boundary]
valid = -0.01 0.01

[blockmaze_weight_final_reward]
goal = 10

[multi_objective]
point = result['point']
color = result['fitness']
